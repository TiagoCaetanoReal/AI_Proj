{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir musicar e pré-processar melspectogram\n",
    "import pandas as pd\n",
    "import librosa as mimosa\n",
    "import audioread\n",
    "import os\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "musicGender = os.listdir(\"musics\") # returns list\n",
    "genderlabel = []\n",
    "musicData = []\n",
    "\n",
    "for gender in musicGender:\n",
    "    genderMusics = os.listdir('./musics/{}'.format(gender))\n",
    "    for music in genderMusics:\n",
    "        genderlabel.append(gender)\n",
    "        \n",
    "        amplitude, sr = mimosa.load('./musics/{}'.format(gender)+'/{}'.format(music), offset=15, duration=15)\n",
    "\n",
    "        melSpec = mimosa.feature.melspectrogram(y = amplitude, sr=sr, n_mels=128, fmax=8000)    \n",
    "        melSpec_to_db = mimosa.power_to_db(melSpec, ref=np.max)\n",
    "        resized_melSpec = np.resize(melSpec_to_db, (melSpec_to_db.shape[0], 1293))\n",
    "        \n",
    "        musicData.append(resized_melSpec)\n",
    "\n",
    "mfcc_specData=np.stack(musicData)\n",
    "musicData=np.array(musicData)\n",
    "genderlabel=np.array(genderlabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazer encoding das categorias\n",
    "import sklearn.preprocessing as preProSkL\n",
    "\n",
    "labelEncoder = preProSkL.LabelEncoder()\n",
    "labelEncoded = labelEncoder.fit(genderlabel)\n",
    "labelEncodedTrans = labelEncoded.transform(genderlabel)\n",
    "# inverse_transform to revert to normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizar dados por media\n",
    "# não usado, mas pode ser comentado\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# sc_X=StandardScaler()\n",
    "# mfcc_specData = sc_X.fit_transform(mfcc_specData)\n",
    "\n",
    "# mfcc_specData.head()\n",
    "\n",
    "\n",
    "# mean = np.mean(musicData, axis=-1, keepdims=True)\n",
    "# std = np.std(musicData, axis=-1, keepdims=True)\n",
    "\n",
    "\n",
    "# Normalize the array by subtracting the mean and dividing by the standard deviation\n",
    "# normalized_data = (musicData - mean) / std\n",
    "\n",
    "# print(len(normalized_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização Min Max\n",
    "\n",
    "indexMin=0\n",
    "indexMax = 100\n",
    "\n",
    "normalized_data = []\n",
    "numCategories = int( len(labelEncodedTrans)/ 100)\n",
    "\n",
    "\n",
    "for i in range(numCategories):\n",
    "\n",
    "    max = mfcc_specData[indexMin:indexMax].max()\n",
    "    min = mfcc_specData[indexMin:indexMax].min()\n",
    "\n",
    "    h = 0\n",
    "    for music in musicData[indexMin:indexMax]:\n",
    "\n",
    "        xScaled = (music - min) / (max - min)\n",
    "        normalized_data.append(xScaled)\n",
    "\n",
    "    indexMin += 100\n",
    "    indexMax += 100  \n",
    "\n",
    "normalized_data=np.array(normalized_data)\n",
    "\n",
    "print(len(normalized_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # modelo usado, atravé da separação dos dados com k-folds\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "# from tensorflow import keras\n",
    "# import matplotlib.pyplot as pyplot\n",
    "\n",
    "# acc_per_fold = []\n",
    "# loss_per_fold = []\n",
    "\n",
    "# input_shape=(normalized_data.shape[1],normalized_data.shape[2],1)\n",
    "# fold_no = 1\n",
    "\n",
    "# kf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "# for train, test in kf.split(normalized_data):\n",
    "#     model=keras.Sequential()\n",
    "\n",
    "#     #1st layer\n",
    "#     model.add(keras.layers.Conv2D(8,(3,3),activation=\"relu\",input_shape=input_shape))\n",
    "#     model.add(keras.layers.MaxPool2D((3,3),strides=(2,2),padding=\"same\")) \n",
    "#     model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "#     # #2nd layer\n",
    "#     # model.add(keras.layers.Conv2D(8,(3,3),activation=\"relu\"))\n",
    "#     # model.add(keras.layers.MaxPool2D((3,3),strides=(2,2),padding=\"same\")) #pooling\n",
    "#     # model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "#     # #3rd layer\n",
    "#     # model.add(keras.layers.Conv2D(8,(1,1),activation=\"relu\"))\n",
    "#     # model.add(keras.layers.MaxPool2D((1,1),strides=(1,1),padding=\"same\")) #pooling\n",
    "#     # model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "#     #flatten the output\n",
    "#     model.add(keras.layers.Flatten())\n",
    "#     model.add(keras.layers.Dense(8,activation=\"relu\"))\n",
    "#     # model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "#     #output layer\n",
    "#     model.add(keras.layers.Dense(3,activation=\"softmax\"))\n",
    "\n",
    "\n",
    "#     optimizer=keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#     model.compile(optimizer=optimizer,\n",
    "#         loss=\"sparse_categorical_crossentropy\",\n",
    "#         metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "#     # Generate a print\n",
    "#     print('------------------------------------------------------------------------')\n",
    "#     print(f'Training for fold {fold_no} ...')\n",
    "        \n",
    "#     # normalized_data[train] = normalized_data[train].reshape((-1, normalized_data[train].shape[1], normalized_data[train].shape[2], 1))\n",
    "#     history = model.fit(normalized_data[train],labelEncodedTrans[train],epochs=25, validation_data=(normalized_data[test], labelEncodedTrans[test]))\n",
    "\n",
    "#     testError, testAccuracy = model.evaluate(normalized_data[test], labelEncodedTrans[test])\n",
    "#     print(\"Accuracy on test set is:{}\".format(testAccuracy))\n",
    "\n",
    "\n",
    "#     print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {testError}; {model.metrics_names[1]} of {testAccuracy*100}%')\n",
    "#     acc_per_fold.append(testAccuracy * 100)\n",
    "#     loss_per_fold.append(testError)\n",
    "\n",
    "#     # Increase fold number\n",
    "#     fold_no = fold_no + 1\n",
    "\n",
    "# # == Provide average scores ==\n",
    "# print('------------------------------------------------------------------------')\n",
    "# print('Score per fold')\n",
    "# for i in range(0, len(acc_per_fold)):\n",
    "#     print('------------------------------------------------------------------------')\n",
    "#     print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "#     print('------------------------------------------------------------------------')\n",
    "#     print('Average scores for all folds:')\n",
    "#     print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "#     print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "#     print('------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def theModel(filters, neurons, data):\n",
    "    input_shape=(data.shape[1],data.shape[2],1)\n",
    "\n",
    "    model=keras.Sequential()\n",
    "\n",
    "    #input layer\n",
    "    model.add(keras.layers.Conv2D(filters,(3,3),activation=\"relu\",input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D((3,3),strides=(2,2),padding=\"same\")) \n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "    #flatten the output\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(filters,activation=\"relu\"))\n",
    "    # model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "    #output layer\n",
    "    model.add(keras.layers.Dense(neurons,activation=\"softmax\"))\n",
    "\n",
    "\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "def trainTestModel(splitNumb, filters, data, labels):\n",
    "    acc_per_fold = []\n",
    "    loss_per_fold = []\n",
    "\n",
    "    fold_no = 1\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=splitNumb, random_state=42, shuffle=True)\n",
    "    for train, test in kf.split(data):\n",
    "        \n",
    "        print(\"index:{}\".format(splitNumb))\n",
    "        print(\"filter:{}\".format(filters))\n",
    "\n",
    "        cnnModel = theModel(filters, splitNumb, data)\n",
    "        \n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "            \n",
    "        history = cnnModel.fit(data[train],labels[train],epochs=25, validation_data=(data[test], labels[test]))\n",
    "\n",
    "        testError, testAccuracy = cnnModel.evaluate(data[test], labels[test])\n",
    "        print(\"Accuracy on test set is:{}\".format(testAccuracy))\n",
    "\n",
    "        print(f'Score for fold {fold_no}: {cnnModel.metrics_names[0]} of {testError}; {cnnModel.metrics_names[1]} of {testAccuracy*100}%')\n",
    "        acc_per_fold.append(testAccuracy * 100)\n",
    "        loss_per_fold.append(testError)\n",
    "\n",
    "        fold_no = fold_no + 1\n",
    "\n",
    "    # == Provide average scores ==\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Score per fold')\n",
    "    for i in range(0, len(acc_per_fold)):\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print('Average scores for all folds:')\n",
    "        print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "        print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "        print('------------------------------------------------------------------------')\n",
    "\n",
    "    return np.mean(acc_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "index = 1\n",
    "filters = 5\n",
    "mappingAccuracy = []\n",
    "\n",
    "\n",
    "for x in range(numCategories):\n",
    "    if index != 1:\n",
    "        for filter in range(filters):\n",
    "            filter += 4\n",
    "            dataInterval =  normalized_data[0:100 * index]\n",
    "            labels = labelEncodedTrans[0:100 * index]\n",
    "            accuracy  = trainTestModel(index, filter, dataInterval, labels)\n",
    "          \n",
    "            mappingAccuracy.append({'acc': math.ceil(accuracy), 'numMusicas': index, 'filtrosCNN': filter})\n",
    "        \n",
    "    index = index + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criar um DataFrame a partir da lista de dicionários\n",
    "df = pd.DataFrame(mappingAccuracy)\n",
    "\n",
    "# Encontrar o elemento com valor máximo de cada categoria\n",
    "elementos_maximos = df.groupby('numMusicas').apply(lambda x: x.loc[x['acc'].idxmax()]).reset_index(drop=True)\n",
    "\n",
    "# Imprimir os elementos com valor máximo de cada categoria\n",
    "for _, elemento in elementos_maximos.iterrows():\n",
    "    print(elemento.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(elementos_maximos['acc'],elementos_maximos['numMusicas'], 'o-')\n",
    "ax1.set_ylabel('Numero de Genros')\n",
    "ax1.set_xlabel('Accuracy')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "zline = elementos_maximos['acc']\n",
    "xline = elementos_maximos['filtrosCNN']\n",
    "yline = elementos_maximos['numMusicas']\n",
    "ax.plot3D(xline, yline, zline, 'gray')\n",
    "\n",
    "# Data for three-dimensional scattered points\n",
    "zdata =  elementos_maximos['acc']\n",
    "xdata = elementos_maximos['filtrosCNN']\n",
    "ydata =  elementos_maximos['numMusicas']\n",
    "ax.set_ylabel('numero de genros')\n",
    "ax.set_xlabel('filtrosCNN')\n",
    "ax.set_zlabel('Accuracy')\n",
    "ax.scatter3D(xdata, ydata, zdata)\n",
    "\n",
    "\n",
    "ax.view_init(elev=20., azim=-45, roll=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separação antiga dos dados de treino e teste\n",
    "\n",
    "# import sklearn.model_selection as modelSelec\n",
    "\n",
    "# X_train, X_test, y_train, y_test = modelSelec.train_test_split(normalized_data, labelEncodedTrans, test_size=0.25, random_state=42)\n",
    "\n",
    "# # X_train, X_test, y_val, y_val = modelSelec.train_test_split(mfcc_specData, labelEncodedTrans, test_size=0.5, random_state=42)\n",
    "# X_test,X_validation,y_test,y_validation=modelSelec.train_test_split(X_test,y_test,test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # criados dos plots/imagens através dos dados normalizados \n",
    "\n",
    "# import matplotlib.pyplot as pyplot\n",
    "\n",
    "# musicCounter = 0\n",
    "\n",
    "# path = './musicsPlts'\n",
    "# if not os.path.exists(path):\n",
    "#     os.mkdir(path)\n",
    "\n",
    "# for gender in musicGender:\n",
    "#     genderPath = '{}'.format(path) + '/{}'.format(gender)\n",
    "#     if not os.path.exists(genderPath):\n",
    "#         os.mkdir(genderPath)\n",
    "\n",
    "# for index in range(len(normalized_data)):\n",
    "#     fig, ax = pyplot.subplots()\n",
    "#     img = mimosa.display.specshow(normalized_data[index], x_axis='time', y_axis='mel', sr=sr, fmax=8000, ax=ax)\n",
    "#     fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "\n",
    "#     ax.set(title='Mel-frequency spectrogram')\n",
    "\n",
    "#     if index % 100 == 0:\n",
    "#         musicCounter = 0\n",
    "    \n",
    "#     pyplot.savefig('{}'.format(path) + '/{}'.format(genderlabel[index]) + '/{}'.format(musicCounter) + '.png')\n",
    "\n",
    "#     musicCounter +=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # formato dos dados para modelo antigo\n",
    "\n",
    "# print(X_train.shape)\n",
    "# input_shape=(X_train.shape[1],X_train.shape[2],1)\n",
    "# print(X_train.shape)\n",
    "# print(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # modelo antigo testado com variantes\n",
    "\n",
    "# from tensorflow import keras\n",
    "\n",
    "# model=keras.Sequential()\n",
    "# #1st layer\n",
    "# model.add(keras.layers.Conv2D(24,(3,3),activation=\"relu\",input_shape=input_shape))\n",
    "# model.add(keras.layers.MaxPool2D((3,3),strides=(2,2),padding=\"same\")) \n",
    "# model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "# #2nd layer\n",
    "# model.add(keras.layers.Conv2D(24,(3,3),activation=\"relu\"))\n",
    "# model.add(keras.layers.MaxPool2D((3,3),strides=(2,2),padding=\"same\")) #pooling\n",
    "# model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "# #3rd layer\n",
    "# model.add(keras.layers.Conv2D(24,(2,2),activation=\"relu\"))\n",
    "# model.add(keras.layers.MaxPool2D((2,2),strides=(2,2),padding=\"same\")) #pooling\n",
    "# model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "# #flatten the output\n",
    "# model.add(keras.layers.Flatten())\n",
    "# model.add(keras.layers.Dense(20,activation=\"relu\"))\n",
    "# model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "# #output layer\n",
    "# model.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "\n",
    "# optimizer=keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# model.compile(optimizer=optimizer,\n",
    "#     loss=\"sparse_categorical_crossentropy\",\n",
    "#     metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  treino do modelo antigo \n",
    "\n",
    "# X_train = X_train.reshape((-1, X_train.shape[1], X_train.shape[2], 1))\n",
    "# print(X_train.shape[0])\n",
    "# # history = model.fit(X_train,y_train,epochs=35, validation_data=(X_validation, y_validation))\n",
    "# history = model.fit(X_train,y_train,epochs=35, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # validação do modelo antigo\n",
    "\n",
    "# import matplotlib.pyplot as pyplot\n",
    "\n",
    "# print(history.history)\n",
    "\n",
    "# testError, testAccuracy = model.evaluate(X_test, y_test)\n",
    "# print(\"Accuracy on test set is:{}\".format(testAccuracy))\n",
    "\n",
    "# pyplot.plot(history.history['accuracy'], label='train_accuracy')\n",
    "# pyplot.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "# pyplot.xlabel('Epoch')\n",
    "# pyplot.ylabel('Accuracy')\n",
    "# pyplot.ylim([0.1, 1.1])\n",
    "# pyplot.legend(loc='lower right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
