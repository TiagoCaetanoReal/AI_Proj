{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrir musicar e pré-processar melspectogram\n",
    "import pandas as pd\n",
    "import librosa as mimosa\n",
    "import audioread\n",
    "import os\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "musicGender = os.listdir(\"musics\") # returns list\n",
    "genderlabel = []\n",
    "musicData = []\n",
    "\n",
    "for gender in musicGender:\n",
    "    genderMusics = os.listdir('./musics/{}'.format(gender))\n",
    "    for music in genderMusics:\n",
    "        genderlabel.append(gender)\n",
    "        \n",
    "        amplitude, sr = mimosa.load('./musics/{}'.format(gender)+'/{}'.format(music))\n",
    "\n",
    "        melSpec = mimosa.feature.melspectrogram(y = amplitude, sr=sr, n_mels=128, fmax=8000)    \n",
    "        melSpec_to_db = mimosa.power_to_db(melSpec, ref=np.max)\n",
    "        resized_melSpec = np.resize(melSpec_to_db, (melSpec_to_db.shape[0], 1293))\n",
    "        \n",
    "        musicData.append(resized_melSpec)\n",
    "\n",
    "mfcc_specData=np.stack(musicData)\n",
    "musicData=np.array(musicData)\n",
    "genderlabel=np.array(genderlabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazer encoding das categorias\n",
    "import sklearn.preprocessing as preProSkL\n",
    "\n",
    "labelEncoder = preProSkL.LabelEncoder()\n",
    "labelEncoded = labelEncoder.fit(genderlabel)\n",
    "labelEncodedTrans = labelEncoded.transform(genderlabel)\n",
    "# inverse_transform to revert to normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizar dados por media\n",
    "# não usado, mas pode ser comentado\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# sc_X=StandardScaler()\n",
    "# mfcc_specData = sc_X.fit_transform(mfcc_specData)\n",
    "\n",
    "# mfcc_specData.head()\n",
    "\n",
    "\n",
    "# mean = np.mean(musicData, axis=-1, keepdims=True)\n",
    "# std = np.std(musicData, axis=-1, keepdims=True)\n",
    "\n",
    "\n",
    "# Normalize the array by subtracting the mean and dividing by the standard deviation\n",
    "# normalized_data = (musicData - mean) / std\n",
    "\n",
    "# print(len(normalized_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[[[0.5783409  0.5788618  0.5487855  ... 0.61045194 0.62712353 0.7378836 ]\n",
      "  [0.62866545 0.66257346 0.66708696 ... 0.6991476  0.73972845 0.7818091 ]\n",
      "  [0.5650602  0.56712735 0.65379363 ... 0.66821975 0.77540904 0.7718417 ]\n",
      "  ...\n",
      "  [0.17659025 0.22293349 0.2625003  ... 0.22600517 0.25689825 0.26358634]\n",
      "  [0.12187986 0.18058339 0.24473663 ... 0.16336517 0.2247715  0.24890284]\n",
      "  [0.08055706 0.15793267 0.23598161 ... 0.1612997  0.23033647 0.23180266]]\n",
      "\n",
      " [[0.5609849  0.60876155 0.7363566  ... 0.6960176  0.63633746 0.6941823 ]\n",
      "  [0.58704716 0.72307044 0.88060904 ... 0.8538593  0.8184128  0.8121853 ]\n",
      "  [0.53404224 0.760989   0.89426595 ... 0.82095623 0.81130344 0.80466497]\n",
      "  ...\n",
      "  [0.         0.12093868 0.24444851 ... 0.34721032 0.32010967 0.32215595]\n",
      "  [0.         0.11132898 0.23897576 ... 0.33503366 0.3226734  0.321418  ]\n",
      "  [0.         0.14814854 0.25449848 ... 0.35689202 0.33806244 0.34973305]]\n",
      "\n",
      " [[0.5630524  0.5390273  0.48941955 ... 0.6870567  0.65241706 0.5791148 ]\n",
      "  [0.6623803  0.62777185 0.5751807  ... 0.7404331  0.6859273  0.64733934]\n",
      "  [0.77198493 0.8267304  0.8390177  ... 0.7304462  0.6897334  0.7183203 ]\n",
      "  ...\n",
      "  [0.32855073 0.3680049  0.35905075 ... 0.31313545 0.3199152  0.3903721 ]\n",
      "  [0.3038827  0.3560567  0.36973763 ... 0.31603035 0.3437458  0.4198257 ]\n",
      "  [0.26796025 0.297122   0.27642164 ... 0.3335763  0.32539684 0.3894531 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.46267232 0.480792   0.45263356 ... 0.487916   0.46178508 0.44309244]\n",
      "  [0.5100181  0.51244146 0.48968202 ... 0.5432283  0.50268996 0.40925455]\n",
      "  [0.5166814  0.4922788  0.48004135 ... 0.52723014 0.51850456 0.40081692]\n",
      "  ...\n",
      "  [0.15075493 0.22052889 0.23246484 ... 0.25182    0.2542581  0.24245062]\n",
      "  [0.10702095 0.14937763 0.16042404 ... 0.23322992 0.23945999 0.24538632]\n",
      "  [0.02212543 0.04618187 0.03163948 ... 0.10491314 0.10238266 0.13210449]]\n",
      "\n",
      " [[0.6279268  0.7114507  0.7474443  ... 0.65819854 0.6651982  0.6225419 ]\n",
      "  [0.7681395  0.81930685 0.7884954  ... 0.6223095  0.64113486 0.5834812 ]\n",
      "  [0.81559455 0.8713684  0.8544601  ... 0.5905049  0.597699   0.6033991 ]\n",
      "  ...\n",
      "  [0.33986798 0.37639493 0.35344172 ... 0.1337473  0.10832167 0.12118416]\n",
      "  [0.29228267 0.3245655  0.31676054 ... 0.13635635 0.11411657 0.11367903]\n",
      "  [0.25845337 0.30090705 0.31598538 ... 0.08478155 0.07508183 0.11371937]]\n",
      "\n",
      " [[0.7226788  0.79941255 0.7603738  ... 0.7440058  0.80501014 0.8516653 ]\n",
      "  [0.80942786 0.909149   0.8964033  ... 0.7611888  0.84673196 0.8544219 ]\n",
      "  [0.8447652  0.93068904 0.9382188  ... 0.82394695 0.84492016 0.81527394]\n",
      "  ...\n",
      "  [0.30994144 0.322121   0.3266551  ... 0.45842332 0.46743783 0.45402703]\n",
      "  [0.22257905 0.22225013 0.24969168 ... 0.42603093 0.44295606 0.42388844]\n",
      "  [0.24757409 0.22976899 0.24377541 ... 0.38548765 0.39913052 0.3722426 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Normalização Min Max\n",
    "\n",
    "indexMin=0\n",
    "indexMax = 100\n",
    "\n",
    "normalized_data = []\n",
    "numCategories = int( len(labelEncodedTrans)/ 100)\n",
    "\n",
    "\n",
    "for i in range(numCategories):\n",
    "\n",
    "    max = mfcc_specData[indexMin:indexMax].max()\n",
    "    min = mfcc_specData[indexMin:indexMax].min()\n",
    "\n",
    "    h = 0\n",
    "    for music in musicData[indexMin:indexMax]:\n",
    "\n",
    "        xScaled = (music - min) / (max - min)\n",
    "        normalized_data.append(xScaled)\n",
    "\n",
    "    indexMin += 100\n",
    "    indexMax += 100  \n",
    "\n",
    "normalized_data=np.array(normalized_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo usado, atravé da separação dos dados com k-folds\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "input_shape=(normalized_data.shape[1],normalized_data.shape[2],1)\n",
    "fold_no = 1\n",
    "\n",
    "kf = KFold(n_splits=4, random_state=42, shuffle=True)\n",
    "for train, test in kf.split(normalized_data):\n",
    "    model=keras.Sequential()\n",
    "    #1st layer\n",
    "    model.add(keras.layers.Conv2D(8,(3,3),activation=\"relu\",input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D((3,3),strides=(2,2),padding=\"same\")) \n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # #2nd layer\n",
    "    # model.add(keras.layers.Conv2D(16,(3,3),activation=\"relu\"))\n",
    "    # model.add(keras.layers.MaxPool2D((3,3),strides=(2,2),padding=\"same\")) #pooling\n",
    "    # model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    #3rd layer\n",
    "    model.add(keras.layers.Conv2D(8,(1,1),activation=\"relu\"))\n",
    "    model.add(keras.layers.MaxPool2D((1,1),strides=(1,1),padding=\"same\")) #pooling\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "    #flatten the output\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(4,activation=\"relu\"))\n",
    "    # model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    #output layer\n",
    "    model.add(keras.layers.Dense(2,activation=\"softmax\"))\n",
    "\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "        \n",
    "    # normalized_data[train] = normalized_data[train].reshape((-1, normalized_data[train].shape[1], normalized_data[train].shape[2], 1))\n",
    "    history = model.fit(normalized_data[train],labelEncodedTrans[train],epochs=25, validation_data=(normalized_data[test], labelEncodedTrans[test]))\n",
    "\n",
    "    testError, testAccuracy = model.evaluate(normalized_data[test], labelEncodedTrans[test])\n",
    "    print(\"Accuracy on test set is:{}\".format(testAccuracy))\n",
    "\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {testError}; {model.metrics_names[1]} of {testAccuracy*100}%')\n",
    "    acc_per_fold.append(testAccuracy * 100)\n",
    "    loss_per_fold.append(testError)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    \n",
    "    # print(\"%s %s\" % (train, test))\n",
    "    # print( len(normalized_data[train]))\n",
    "    # print( len(normalized_data[test]))\n",
    "\n",
    "# print(normalized_data[train])\n",
    "# X_train, X_test, y_train, y_test = normalized_data[train], normalized_data[test], labelEncodedTrans[train], labelEncodedTrans[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separação antiga dos dados de treino e teste\n",
    "\n",
    "# import sklearn.model_selection as modelSelec\n",
    "\n",
    "# X_train, X_test, y_train, y_test = modelSelec.train_test_split(normalized_data, labelEncodedTrans, test_size=0.25, random_state=42)\n",
    "\n",
    "# # X_train, X_test, y_val, y_val = modelSelec.train_test_split(mfcc_specData, labelEncodedTrans, test_size=0.5, random_state=42)\n",
    "# X_test,X_validation,y_test,y_validation=modelSelec.train_test_split(X_test,y_test,test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot do mel spectogram\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = pyplot.subplots()\n",
    "img = mimosa.display.specshow(normalized_data[100], x_axis='time', y_axis='mel', sr=sr, fmax=8000, ax=ax)\n",
    "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "\n",
    "ax.set(title='Mel-frequency spectrogram')\n",
    "\n",
    "pyplot.savefig('0.png')\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criados dos plots através dos dados normalizados \n",
    "\n",
    "# import matplotlib.pyplot as pyplot\n",
    "\n",
    "# musicCounter = 0\n",
    "\n",
    "# path = './musicsPlts'\n",
    "# if not os.path.exists(path):\n",
    "#     os.mkdir(path)\n",
    "\n",
    "# for gender in musicGender:\n",
    "#     genderPath = '{}'.format(path) + '/{}'.format(gender)\n",
    "#     if not os.path.exists(genderPath):\n",
    "#         os.mkdir(genderPath)\n",
    "\n",
    "# for index in range(len(mfcc_specData)):\n",
    "#     fig, ax = pyplot.subplots()\n",
    "#     img = mimosa.display.specshow(mfcc_specData[index], x_axis='time', y_axis='mel', sr=sr, fmax=8000, ax=ax)\n",
    "#     fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "\n",
    "#     ax.set(title='Mel-frequency spectrogram')\n",
    "\n",
    "#     if index % 100 == 0:\n",
    "#         musicCounter = 0\n",
    "    \n",
    "#     pyplot.savefig('{}'.format(path) + '/{}'.format(genderlabel[index]) + '/{}'.format(musicCounter) + '.png')\n",
    "\n",
    "#     musicCounter +=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formato dos dados para modelo antigo\n",
    "\n",
    "print(X_train.shape)\n",
    "input_shape=(X_train.shape[1],X_train.shape[2],1)\n",
    "print(X_train.shape)\n",
    "print(input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo antigo testado com variantes\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "model=keras.Sequential()\n",
    "#1st layer\n",
    "model.add(keras.layers.Conv2D(24,(3,3),activation=\"relu\",input_shape=input_shape))\n",
    "model.add(keras.layers.MaxPool2D((3,3),strides=(2,2),padding=\"same\")) \n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "#2nd layer\n",
    "model.add(keras.layers.Conv2D(24,(3,3),activation=\"relu\"))\n",
    "model.add(keras.layers.MaxPool2D((3,3),strides=(2,2),padding=\"same\")) #pooling\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "#3rd layer\n",
    "model.add(keras.layers.Conv2D(24,(2,2),activation=\"relu\"))\n",
    "model.add(keras.layers.MaxPool2D((2,2),strides=(2,2),padding=\"same\")) #pooling\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "#flatten the output\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(20,activation=\"relu\"))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "#output layer\n",
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "\n",
    "optimizer=keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  treino do modelo antigo \n",
    "\n",
    "X_train = X_train.reshape((-1, X_train.shape[1], X_train.shape[2], 1))\n",
    "print(X_train.shape[0])\n",
    "# history = model.fit(X_train,y_train,epochs=35, validation_data=(X_validation, y_validation))\n",
    "history = model.fit(X_train,y_train,epochs=35, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validação do modelo antigo\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "print(history.history)\n",
    "\n",
    "testError, testAccuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Accuracy on test set is:{}\".format(testAccuracy))\n",
    "\n",
    "pyplot.plot(history.history['accuracy'], label='train_accuracy')\n",
    "pyplot.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('Accuracy')\n",
    "pyplot.ylim([0.1, 1.1])\n",
    "pyplot.legend(loc='lower right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
